{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e736e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b409c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>müller mox figura centralis circulorum doctoru...</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>برقی بار electric charge تمام زیرجوہری ذرات کی...</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
       "6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
       "7  müller mox figura centralis circulorum doctoru...     Latin\n",
       "8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
       "9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e40a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      22000 non-null  object\n",
      " 1   language  22000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21141f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70560d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Estonian', 'Swedish', 'Thai', 'Tamil', 'Dutch', 'Japanese',\n",
       "       'Turkish', 'Latin', 'Urdu', 'Indonesian', 'Portugese', 'French',\n",
       "       'Chinese', 'Korean', 'Hindi', 'Spanish', 'Pushto', 'Persian',\n",
       "       'Romanian', 'Russian', 'English', 'Arabic'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b1df7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5861a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.Text,df.language,train_size=0.7,random_state=42,stratify=df.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032b386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ed963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582146b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer( max_features=10000)\n",
    "count_train = cv.fit_transform(x_train)\n",
    "count_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b323992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15399, 10000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a6fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.A\n",
    "#df = pd.DataFrame.sparse.from_spmatrix(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d4f8de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aan', 'aantal', 'aasta', ..., '힘을', '힘이', 'ﭼﯥ'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "367bcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df_train=pd.DataFrame(count_train.A,columns=cv.get_feature_names_out())\n",
    "cv_df_test =pd.DataFrame(count_test.A,columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20a86ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67d36825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MultinomialNB()\n",
    "model.fit(cv_df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9be33469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209039548022598\n",
      "0.9198606271777003\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_train = model.predict(cv_df_train)\n",
    "y_pred_cv_test = model.predict(cv_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_cv_train))\n",
    "print(accuracy_score(y_test,y_pred_cv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f7b743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b937c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6492697c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15399, 10000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9bb4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325930255211378\n",
      "0.9269807604908348\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=20000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9aa3c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 261)\n",
      "0.8253133320345477\n",
      "0.8297227692773822\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=0.95, min_df=0.01, max_features=20000)   #### reduced feature\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546644d6",
   "metadata": {},
   "source": [
    "steps involve :\n",
    "    1. tokenization (can be done on all languages)\n",
    "    2. cleaning (isalpha need to check\n",
    "    3. normalization\n",
    "    4. stopward removal\n",
    "    5. lemmantization\n",
    "    6. vectorization\n",
    "    7. model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ddc9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef409dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tozenization(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6c4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text=df.Text.apply(tozenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d06a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42739b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(da):\n",
    "    all_text=[]\n",
    "    for  i in da:\n",
    "        for j in i:\n",
    "            all_text.append(j)\n",
    "    return len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22c01161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191523"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda92575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def cleaning(data):\n",
    "    cleaned = [i for i in data if i not in punctuation]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efb0e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isalpha(data):\n",
    "    isalpha = [i for i in data if i.isalpha()]\n",
    "    return isalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae4cb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    normalized = [i.lower() for i in data]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d814048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18860    진언과 필사탁은 당초 양주 근처의 동당東塘으로 달아나려 하였으나 그때 동당을 점거한...\n",
       "459      vitaminum est compositum organicum quod inest ...\n",
       "10016    \"inclusive democracy\" entry in routledge encyc...\n",
       "6331     السبب في هذا النشاط البركاني وتكوين الينابيع ا...\n",
       "12500    வீனஸ் வில்லியம்ஸ் venus williams பிறப்பு- ஜூன்...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ea7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = x_train.apply(tozenization)\n",
    "tokens_test = x_test.apply(tozenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dadb587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833288\n"
     ]
    }
   ],
   "source": [
    "print(count(tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f345f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829322\n"
     ]
    }
   ],
   "source": [
    "cleaned_train = tokens_train.apply(cleaning)\n",
    "cleaned_test = tokens_test.apply(cleaning)\n",
    "print(count(cleaned_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f60a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710293\n"
     ]
    }
   ],
   "source": [
    "alpha_train = cleaned_train.apply(isalpha)\n",
    "alpha_test = cleaned_test.apply(isalpha)\n",
    "print(count(alpha_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e246dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18552    [pasimasunggu, timur, adalah, sebuah, kecamata...\n",
       "13180    [infected, türkçe, enfekte, olan, kıyamet, son...\n",
       "52       [tussen, een, kruising, in, het, westen, van, ...\n",
       "2370     [inlandsklimat, råder, i, trakten, årsmedeltem...\n",
       "21674    [gardaneh-ye, mandānak, persiska, گردنه, مندان...\n",
       "16934    [نگاوا, تبتی, اور, چیانگ, خود, مختار, پریفیکچر...\n",
       "19791    [farrington, d, p, a, predicting, adult, offic...\n",
       "5414     [hispana, christianitatium, catholicorum, roma...\n",
       "1785     [david, daniel, kaminsky, mer, känd, under, ar...\n",
       "20710    [년융희, 년, 월, 고희경高羲敬, 정응고鄭應高, 등과, 함께, 정우회政友會를, 조...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d7d4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000     [وكونه, عبر, يلوستون, وشهد, مشاكل, إدارة, الأر...\n",
       "20431    [in, hamilton, started, playing, sporadic, aco...\n",
       "11348    [وی, همچنین, در, تاریخ, آوریل, اردیبهشت, در, د...\n",
       "15644    [년, 월, 일, 디즈니는, 피니와, 퍼브, tv, 영화를, 제작한다고, 밝혔으며,...\n",
       "16452    [georg, november, celle, aprill, hildesheim, o...\n",
       "10541    [sob, o, reinado, dos, reis, carolíngios, o, f...\n",
       "8622                                                    []\n",
       "11260    [la, salsa, incluye, trufas, y, setas, finamen...\n",
       "6259     [malgré, son, admiration, pour, de, gaulle, de...\n",
       "9086     [the, paper, is, noted, as, the, last, place, ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_train.sample(10)  ### so we can't apply is.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c629ae22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829322\n"
     ]
    }
   ],
   "source": [
    "normalize_train = cleaned_train.apply(normalize)\n",
    "normalize_test = cleaned_test.apply(normalize)\n",
    "print(count(normalize_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce85a56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10265    [கிவி, kiwi, என்பது, நியூசிலாந்தில், வாழும், அ...\n",
       "21323    [マキの家庭教師が結婚で辞めるのを機に塾に通わせようとする。もともと「男子がいるから」という...\n",
       "16616    [年，小说的意大利出版商皮埃美（piemme）联系了胡赛尼，希望能将小说原著改编成漫画小说。...\n",
       "4685     [–, sekarang, pengajarnarasumber, pada, kursus...\n",
       "3673     [after, a, few, transition, years, in, india, ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e45c5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now convert to sprint again with join function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2ea80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(data):\n",
    "    string = ' '.join(data)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d914c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458192\n"
     ]
    }
   ],
   "source": [
    "join_train = normalize_train.apply(join)\n",
    "join_test = normalize_test.apply(join)\n",
    "print(count(join_train))  ### count of all string characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb0a2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17136    kiraŭsk transkribeerituna kiravsk on linn valg...\n",
       "2777     پاکو تا سال قادر به خواندن نت نبود و چنان‌که د...\n",
       "13468    มีประชาธิปไตยกึ่งโดยตรงบางรูปแบบ ที่ผู้แทนจะบร...\n",
       "3380     لومړنۍ دنده يې په ل کې له سرکاري ملازمته پيل ک...\n",
       "10891    her havaalanına ils sistemi kurulamaz havaalan...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f05148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 20000)\n",
      "0.932982661211767\n",
      "0.926071807301924\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=20000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(join_train)\n",
    "tf_test = tf.transform(join_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dff0bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bad      good    habbit   quality\n",
      "0  0.000000  0.707107  0.000000  0.707107\n",
      "1  0.707107  0.000000  0.707107  0.000000\n",
      "['pos' 'neg']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=20000)\n",
    "tf_train = tf.fit_transform(['good quality','bad habbit'])\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "print(tf_df_train)\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,['pos','neg'])\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "\n",
    "print(y_pred_tf_train)\n",
    "print(accuracy_score(['pos','neg'],y_pred_tf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bead2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create picket files of tfidfvectorize and MultinominalNB\n",
    "\n",
    "import pickle\n",
    "\n",
    "file =  open('tfidfvectorize.pkl','wb')\n",
    "pickle.dump(tf,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b8a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file =  open('MultinominalNB.pkl','wb')\n",
    "pickle.dump(model,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d20add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aabdel  aan  aangebracht  aansluit  aansluiting  aantal  aanvallen  aasta  \\\n",
      "0     0.0  0.0          0.0       0.0          0.0     0.0        0.0    0.0   \n",
      "\n",
      "   aastad  aastail  ...  휘하의  흑마법  흑마법을   힘을   힘이   ﭘﻪ   ﭼﯥ  ﮐړﯼ  ﺍﻟﻠﻪ  ﺗﺎﺳﯽ  \n",
      "0     0.0      0.0  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "\n",
      "[1 rows x 20000 columns]\n",
      "predicted language is : ['Russian']\n"
     ]
    }
   ],
   "source": [
    "tf_train = tf.transform(['года'])\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "print(tf_df_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "\n",
    "print(f'predicted language is :', y_pred_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41794636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4857     [-களில், விவசாயத்தை, மட்டுமே, நம்பி, இருந்த, ஆ...\n",
       "16828    [«, یکی, از, شرایط, شرعی, نفوذ, اقرار, عدم, اک...\n",
       "11888    [ख़ज़रेत​, सुलतान, या, हज़रत, सुलतान, अंग्रेज़...\n",
       "57       [en, application, du, schéma, départemental, d...\n",
       "14371    [стал, известен, в, феврале, года, когда, неза...\n",
       "11623    [ஒருமுறை, முசுகுந்த, சோழனுக்கு, தீராத, தோல், ந...\n",
       "2235     [tv, dizilerinde, en, i̇yi, kadın, oyuncu, alt...\n",
       "3898     [-இல், நிறுவப்பட்ட, நங்கானா, சாகிபு, மாவட்டம்,...\n",
       "14300    [os, escritos, de, peregrinos, indicam, que, o...\n",
       "15761    [九州の事業者らしく、西日本車体工業（西工）ボディを架装する車両も多いが、年（平成年）以降は...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23e91c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russian'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language[14371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288b0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
