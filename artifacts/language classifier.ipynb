{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e736e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b409c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>müller mox figura centralis circulorum doctoru...</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>برقی بار electric charge تمام زیرجوہری ذرات کی...</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
       "6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
       "7  müller mox figura centralis circulorum doctoru...     Latin\n",
       "8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
       "9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e40a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      22000 non-null  object\n",
      " 1   language  22000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21141f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70560d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Estonian', 'Swedish', 'Thai', 'Tamil', 'Dutch', 'Japanese',\n",
       "       'Turkish', 'Latin', 'Urdu', 'Indonesian', 'Portugese', 'French',\n",
       "       'Chinese', 'Korean', 'Hindi', 'Spanish', 'Pushto', 'Persian',\n",
       "       'Romanian', 'Russian', 'English', 'Arabic'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1df7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5861a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.Text,df.language,train_size=0.7,random_state=42,stratify=df.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032b386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ed963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer( max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "582146b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = cv.fit_transform(x_train)\n",
    "count_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b323992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15399, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4a6fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.A\n",
    "#df = pd.DataFrame.sparse.from_spmatrix(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d4f8de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aan', 'aantal', 'aasta', ..., '힘을', '힘이', 'ﭼﯥ'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "367bcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df_train=pd.DataFrame(count_train.A,columns=cv.get_feature_names_out())\n",
    "cv_df_test =pd.DataFrame(count_test.A,columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a86ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67d36825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MultinomialNB()\n",
    "model.fit(cv_df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9be33469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209039548022598\n",
      "0.9198606271777003\n"
     ]
    }
   ],
   "source": [
    "y_pred_cv_train = model.predict(cv_df_train)\n",
    "y_pred_cv_test = model.predict(cv_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_cv_train))\n",
    "print(accuracy_score(y_test,y_pred_cv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f7b743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b937c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6492697c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15399, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbe15f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938827196571206\n",
      "0.9295561278594152\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=30000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b30cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9434378855769855\n",
      "0.9318285108316922\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=40000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9bb4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9499318137541399\n",
      "0.9328889562187548\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=60000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aa3c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 261)\n",
      "0.8253133320345477\n",
      "0.8297227692773822\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=0.95, min_df=0.01, max_features=20000)   #### reduced feature\n",
    "\n",
    "tf_train = tf.fit_transform(x_train)\n",
    "tf_test = tf.transform(x_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546644d6",
   "metadata": {},
   "source": [
    "steps involve :\n",
    "    1. tokenization (can be done on all languages)\n",
    "    2. cleaning (isalpha need to check\n",
    "    3. normalization\n",
    "    4. stopward removal\n",
    "    5. lemmantization\n",
    "    6. vectorization\n",
    "    7. model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ddc9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef409dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tozenization(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "951da0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    klement gottwaldi surnukeha palsameeriti ning ...\n",
       "1    sebes joseph pereira thomas  på eng the jesuit...\n",
       "2    ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...\n",
       "3    விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...\n",
       "4    de spons behoort tot het geslacht haliclona en...\n",
       "5    エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...\n",
       "6    tsutinalar i̇ngilizce tsuutina kanadada albert...\n",
       "7    müller mox figura centralis circulorum doctoru...\n",
       "8    برقی بار electric charge تمام زیرجوہری ذرات کی...\n",
       "9    シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa6c4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text=df.Text.apply(tozenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "348959c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [klement, gottwaldi, surnukeha, palsameeriti, ...\n",
       "1    [sebes, joseph, pereira, thomas, på, eng, the,...\n",
       "2    [ถนนเจริญกรุง, อักษรโรมัน, thanon, charoen, kr...\n",
       "3    [விசாகப்பட்டினம், தமிழ்ச்சங்கத்தை, இந்துப், பத...\n",
       "4    [de, spons, behoort, tot, het, geslacht, halic...\n",
       "5    [エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと...\n",
       "6    [tsutinalar, i̇ngilizce, tsuutina, kanadada, a...\n",
       "7    [müller, mox, figura, centralis, circulorum, d...\n",
       "8    [برقی, بار, electric, charge, تمام, زیرجوہری, ...\n",
       "9    [シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "393f295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bd8f472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に隣接してある。年にマーティン高校と共に建設された。ラレド独立学区のアウトドア・アスレチックがあり、毎年ボーダー・オリンピックが開催される。通常席だが、エンドゾーンに追加席を加えることで席まで拡大できる。メキシコのプロ・サッカークラブがここで様々な練習試合を行い、天然芝が「良い」サッカー試合を作るとしている。フットボール、サッカーおよび陸上競技が行われる。この歴史ある競技場に大きな改修工事が計画されている。']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d06a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f42739b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(da):\n",
    "    all_text=[]\n",
    "    for  i in da:\n",
    "        for j in i:\n",
    "            all_text.append(j)\n",
    "    return len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22c01161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191523"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cda92575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def cleaning(data):\n",
    "    cleaned = [i for i in data if i not in punctuation]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efb0e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isalpha(data):\n",
    "    isalpha = [i for i in data if i.isalpha()]\n",
    "    return isalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae4cb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    normalized = [i.lower() for i in data]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d814048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18860    진언과 필사탁은 당초 양주 근처의 동당東塘으로 달아나려 하였으나 그때 동당을 점거한...\n",
       "459      vitaminum est compositum organicum quod inest ...\n",
       "10016    \"inclusive democracy\" entry in routledge encyc...\n",
       "6331     السبب في هذا النشاط البركاني وتكوين الينابيع ا...\n",
       "12500    வீனஸ் வில்லியம்ஸ் venus williams பிறப்பு- ஜூன்...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9ea7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = x_train.apply(tozenization)\n",
    "tokens_test = x_test.apply(tozenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dadb587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833288\n"
     ]
    }
   ],
   "source": [
    "print(count(tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f345f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829322\n"
     ]
    }
   ],
   "source": [
    "cleaned_train = tokens_train.apply(cleaning)\n",
    "cleaned_test = tokens_test.apply(cleaning)\n",
    "print(count(cleaned_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f60a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710293\n"
     ]
    }
   ],
   "source": [
    "alpha_train = cleaned_train.apply(isalpha)\n",
    "alpha_test = cleaned_test.apply(isalpha)\n",
    "print(count(alpha_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e246dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21704    [carvajal, made, his, la, liga, debut, on, aug...\n",
       "13824    [ноября, года, римский, папа, иоанн, павел, ii...\n",
       "7169     [harry, soref, founded, the, master, lock, com...\n",
       "18341    [京成・京急・都の者での協議の結果、軌間はmmに決定。そのため、京成電鉄では全線を工程工区に...\n",
       "14344    [r, इतना, बड़ा, होना, चाहिए, ताकि, d, के, माध्...\n",
       "21884    [पराग, बैंक, में, पराग, कण, को, संग्रह, किया, ...\n",
       "5478     [banjir, yang, terus, menerus, terjadi, membua...\n",
       "9760     [سینٹرل, پارک, ٹاورز, انگریزی, central, park, ...\n",
       "21271    [बीज, रोपण, समय, और, फसलों, का, चुनाव, निश्चित...\n",
       "18298    [etkinlik, kadınlar, arasında, yapılan, team, ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d7d4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644                                                     []\n",
       "16519    [à, des, enfants, ont, une, atteinte, bilatéra...\n",
       "19321    [sob, certos, aspectos, olinda, rivalizava, co...\n",
       "7159     [gs, bucher, the, origins, program, and, compo...\n",
       "8275     [siyasal, bilgiler, fakültesi, mezunudur, beyo...\n",
       "1943     [مختلط, اقتصاد, په, انگرېزي, ژبه, کې, mixed, e...\n",
       "13525    [mängis, ta, telekanali, pbs, lühisarjas, maai...\n",
       "10814                                                   []\n",
       "17983    [între, timp, watson, a, redevenit, comis, voi...\n",
       "10102                         [hebe, haven, பல, பல, clubs]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_train.sample(10)  ### so we can't apply is.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c629ae22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829322\n"
     ]
    }
   ],
   "source": [
    "normalize_train = cleaned_train.apply(normalize)\n",
    "normalize_test = cleaned_test.apply(normalize)\n",
    "print(count(normalize_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce85a56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3068     [år, fastställdes, officiella, stadsdelar, inn...\n",
       "6092     [michel, debré, étudie, à, paris, au, lycée, m...\n",
       "19459    [pärast, murru, vangimaja, asutamist, aastal, ...\n",
       "1110     [غير, أن, المماليك, حشدوا, صفوفهم, وهيأوا, الف...\n",
       "8067     [a, lock, is, a, mechanical, or, electronic, f...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now convert to sprint again with join function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e2ea80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(data):\n",
    "    string = ' '.join(data)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05d914c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458192\n"
     ]
    }
   ],
   "source": [
    "join_train = normalize_train.apply(join)\n",
    "join_test = normalize_test.apply(join)\n",
    "print(count(join_train))  ### count of all string characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb0a2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13029    답 여기서는 열반을 말하지 않아야 한다 다만 중생이 과보로서 머무를 곳만을 분별해야...\n",
       "10293    oliver wendell holmes martii — martii fuit iur...\n",
       "10849    itu yang membuat kiprah politiknya menjulang t...\n",
       "1824     august matematicieni americani de la universit...\n",
       "5387     dokuz eylül üniversitesi güzel sanatlar fakült...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b993a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 261)\n",
      "0.8253782713163192\n",
      "0.8297227692773822\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=0.95, min_df=0.01, max_features=20000)   #### reduced feature\n",
    "\n",
    "tf_train = tf.fit_transform(join_train)\n",
    "tf_test = tf.transform(join_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f05148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 20000)\n",
      "0.932982661211767\n",
      "0.926071807301924\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=20000)   #### with more featrure\n",
    "\n",
    "tf_train = tf.fit_transform(join_train)\n",
    "tf_test = tf.transform(join_test)\n",
    "\n",
    "print(tf_train.shape)\n",
    "\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "tf_df_test =pd.DataFrame(tf_test.A,columns=tf.get_feature_names_out())\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,y_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "y_pred_tf_test = model.predict(tf_df_test)\n",
    "\n",
    "print(accuracy_score(y_train,y_pred_tf_train))\n",
    "print(accuracy_score(y_test,y_pred_tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dff0bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bad      good    habbit   quality\n",
      "0  0.000000  0.707107  0.000000  0.707107\n",
      "1  0.707107  0.000000  0.707107  0.000000\n",
      "['pos' 'neg']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(max_df=1.0, min_df=1, max_features=20000)\n",
    "tf_train = tf.fit_transform(['good quality','bad habbit'])\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "print(tf_df_train)\n",
    "\n",
    "model=MultinomialNB()\n",
    "model.fit(tf_df_train,['pos','neg'])\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "\n",
    "print(y_pred_tf_train)\n",
    "print(accuracy_score(['pos','neg'],y_pred_tf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bead2209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aabdel</th>\n",
       "      <th>aan</th>\n",
       "      <th>aangebracht</th>\n",
       "      <th>aansluit</th>\n",
       "      <th>aansluiting</th>\n",
       "      <th>aantal</th>\n",
       "      <th>aanvallen</th>\n",
       "      <th>aasta</th>\n",
       "      <th>aastad</th>\n",
       "      <th>aastail</th>\n",
       "      <th>...</th>\n",
       "      <th>휘하의</th>\n",
       "      <th>흑마법</th>\n",
       "      <th>흑마법을</th>\n",
       "      <th>힘을</th>\n",
       "      <th>힘이</th>\n",
       "      <th>ﭘﻪ</th>\n",
       "      <th>ﭼﯥ</th>\n",
       "      <th>ﮐړﯼ</th>\n",
       "      <th>ﺍﻟﻠﻪ</th>\n",
       "      <th>ﺗﺎﺳﯽ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15399 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aabdel  aan  aangebracht  aansluit  aansluiting  aantal  aanvallen  \\\n",
       "0         0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "1         0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "2         0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "3         0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "4         0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "...       ...  ...          ...       ...          ...     ...        ...   \n",
       "15394     0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "15395     0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "15396     0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "15397     0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "15398     0.0  0.0          0.0       0.0          0.0     0.0        0.0   \n",
       "\n",
       "       aasta  aastad  aastail  ...  휘하의  흑마법  흑마법을        힘을   힘이   ﭘﻪ   ﭼﯥ  \\\n",
       "0        0.0     0.0      0.0  ...  0.0  0.0   0.0  0.225239  0.0  0.0  0.0   \n",
       "1        0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "2        0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "3        0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "4        0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "...      ...     ...      ...  ...  ...  ...   ...       ...  ...  ...  ...   \n",
       "15394    0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "15395    0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "15396    0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "15397    0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "15398    0.0     0.0      0.0  ...  0.0  0.0   0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "       ﮐړﯼ  ﺍﻟﻠﻪ  ﺗﺎﺳﯽ  \n",
       "0      0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0  \n",
       "...    ...   ...   ...  \n",
       "15394  0.0   0.0   0.0  \n",
       "15395  0.0   0.0   0.0  \n",
       "15396  0.0   0.0   0.0  \n",
       "15397  0.0   0.0   0.0  \n",
       "15398  0.0   0.0   0.0  \n",
       "\n",
       "[15399 rows x 20000 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aangebracht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2d20add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aabdel  aan  aangebracht  aansluit  aansluiting  aantal  aanvallen  aasta  \\\n",
      "0     0.0  0.0          0.0       0.0          0.0     0.0        0.0    0.0   \n",
      "\n",
      "   aastad  aastail  ...  휘하의  흑마법  흑마법을   힘을   힘이   ﭘﻪ   ﭼﯥ  ﮐړﯼ  ﺍﻟﻠﻪ  ﺗﺎﺳﯽ  \n",
      "0     0.0      0.0  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
      "\n",
      "[1 rows x 20000 columns]\n",
      "predicted language is : ['Pushto']\n"
     ]
    }
   ],
   "source": [
    "tf_train = tf.transform(['شوي'])\n",
    "tf_df_train=pd.DataFrame(tf_train.A,columns=tf.get_feature_names_out())\n",
    "print(tf_df_train)\n",
    "\n",
    "y_pred_tf_train = model.predict(tf_df_train)\n",
    "\n",
    "print(f'predicted language is :', y_pred_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41794636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836      [இரண்டாம், உலகப்போருக்குப்பின், சோவியத், இராணு...\n",
       "1695     [スパイトフルは、イギリス空軍の主力戦闘機スピットファイアに高出力エンジンを搭載するにあたっ...\n",
       "7411     [불타는, 군단burning, legion, 타락한, 티탄, 살게라스가, 세계정복을...\n",
       "18981    [شمس, تبريز, بابا, يو, لوړ, سوفي, تير, شوي, ده...\n",
       "15033    [balls, foi, assessor-chefe, econômico, do, te...\n",
       "7893     [araneus, tenerius, este, o, specie, de, păian...\n",
       "1351     [年の設立当初は、フィラデルフィアのセンターシティにキャンパスを構えていたが、年に現在の場所...\n",
       "205      [de, meeste, applicatieframeworks, voor, windo...\n",
       "8048     [comete, scurt, periodice, sunt, comete, ce, a...\n",
       "11013    [बांग्लादेश, के, मुख्य, न्यायाधीश, का, पद, बां...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "23e91c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pushto'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language[18981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288b0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
